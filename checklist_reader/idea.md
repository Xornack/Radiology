# Background
Code LLMs like ChatGPT, Gemini CLI, and Claude Code work best when a detailed checklist is there for them to refer to, a place like short-term memory and always within their context window if done right.

# Radiology Application
We run down a list of organ systems (at least I do) in a detailed search pattern. A lof of that search pattern is embedded in the structure of a structured report. However, many details are left out.

# Idea
You could make an incredibly-detailed item-by-item checklist, and instead of the reader checking items off one by one, perhaps a combination of LLM reading your report and eye tracking (?) or other mechanism, like dictating what you are looking at, which will later be removed to make the reports cleaner (also automatic), could make sure you got through your checklist.

# Possible Upsides
- Brings your actions into actively 'doing looking'
- If you get interrrupted, you know where to pick up again, and you can be sure you didn't miss looking at something up to that point.
- Hopfully, will decrease misses.

# Possible Downsides
- Might take extra time - factor that should be considered in any assessment of this idea.
- Requires extra resources/software --> cost. Freeware still has opportunity cost, though would be pretty cheap.
